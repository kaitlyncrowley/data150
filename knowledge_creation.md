#In Class Essay: Knowledge Creation

	Human development is an inherently complex concept.  Development does not just have to do with economic growth, or social change, changing political parties, or even just individual freedoms.  Instead, it is a complex system of all of these factors combined.  These complex adaptive economic and social systems are ever-changing and evolving in response to conditions in society and it is their nature to actually trend toward greater complexity as they develop, according to Owen Barder.  It therefore is necessary that methods of measurement for these complexities are created so that we, as humans, are better able to understand and quantify the complex nature of the world around us.  Only through this detailed, accurate understanding will we be able to address different problems within the systems and come to accurate conclusions.  Data and data science provide a path toward this greater understanding by quantifying processes that would otherwise be too complex to see and analyze in their entirety and creating patterns where there would otherwise be chaos.  There have been significant advances in technology and methods to be able to explain these processes, but it is important to note that these are not without their own faults and obstacles.
	Many times, it seems that the world around us is developing in ways that are too complex to find patterns in.  This can become overwhelming and lead to an inability to address the multitude of inequalities and problems that exist around the world.  However, as Geoff West explains throughout his book, there is actually an underlying order to many of the complexities in the world.  It is through the advent of data science that this conclusions can be reached.  This order could be called an emergent behavior according to West, which is the pattern that results from the combination of many individual parts of a process.  In being able to see patterns in scaling, such as sublinear and superlinear scaling, these seemingly complex patterns become much simpler.  For example, West writes that the development of cities can be better explained by the fact that cities scale sublinearly in terms of infrastructure, meaning that, if a city is larger, the number of roads, pipes, or other infrastructure needed in proportion to the population is actually less than a smaller city.  This relates back to basic biological structures, where larger organisms actually have lower rates of metabolic processes and need proportionally fewer calories, 25% less to be exact.  In terms of superlinear scaling of socioeconomic processes, larger cities have 15% more wealth, jobs, and institutions than linear models would predict.  Having the ability to describe these patterns and processes comes through the use of data collection methods that are able to find these patterns, which can then be applied to other areas.  Big data methods allow for models and theories such as these to be refined and tested.  
	When we, as humans are able to see that cities within an urban system in a nation follow these particular scaling patterns, this pattern of measurement then allows us to understand why the systems of individual cities work the way that they do.  Then, through these observations, as Kitchen argues, new scientific revolutions can be created, due to these new methods of measurement, in order to address particular problems that tend to occur in cities of specific size.  Superlinear scaling of socioeconomic factors does not only include positive elements of society, but also the negative ones such as crime.  If humans are able to describe and predict patterns in the process of socioeconomic development, scientific development could progress in such a way that hypotheses are created to address crime that could then apply to all cities of similar size, or the solution could even be scaled to address the problem.  Similarly, epidemics such as AIDS could be addressed in cities in a more efficient manner since the severity of the epidemic could be predicted according to city size
	The importance of this idea of scaling can also clearly be seen in the 2020 presidential election.  The electoral process is clearly a complex one, with so many different factors affecting the way that a person may choose to vote.  However, through data science, pollsters and reporters are able to try to predict who is going to win by county, state, and ultimately the country.  This is due to an intricate process of data collection and organization to determine the demographics of an area, its past history of voting, and other factors that affect the political outcome of an election.  In recent days, we have seen how reporters are able to scale the results in one county to other counties across the country that share similar attributes.  If one smaller metropolitan area leans blue, West’s concept of superlinear scaling suggests that larger cities will lean towards voting for Joe Biden, likely at an even greater rate due to the 15% increase proposed.  Having these measurement and prediction techniques allows for people to begin to understand the complex reasoning behind the results of an election.  Many reporters, in the early hours of the election results, were able to predict how counties with later polling closes would turn based on similar counties or states and past data collection, relating once again to the concept of scaling.  The scaling can even be applied to how many eligible voters will go to the polls and how many will vote by mail, if they vote at all, based on the patterns in other similar areas and registration data that can be accessed.  In the future, I would hope that more advanced data science methods could be introduced to decrease the likelihood of inaccurate predictions in the political arena.  By combining more data science methods with the concept of scale behavior, the correlation between factors on different levels of scale could be increased to greater certainty, thereby increasing our ability to see the connections between seemingly different parts of the country in terms of individual and community behavior.
	Similarly, the complexity of democratic elections could be seen in the film An African Election.  In this film, or at least the first part of it, the complexities of the election process led to a lot of room for fraud and manipulation of the ballots, undermining the integrity of the election.  In this case, the need for increased data technologies and methodologies that can not only count votes, but possibly detect where or when fraud occurs possibly through methods such as neural networks is clear.  In both this current election, and the election in Ghana, however, the complexities of an election season could be described in terms of percentages and data, even before the physical votes came in.  It is important to note though that this data and data analysis is not always accurate.
	In examples, including that of the election process, the use of data science can be concerning when looking for causation and reasoning for why certain patterns occur in complex systems.  While Kitchen does assert that areas such as political science, which relate to the election issues, tend to “focus on factual, quantified information,” which comes from the concept of positivism, he still emphasizes that data cannot replace theory.  There is a danger that if people begin to rely too much on data, the reasoning behind why problems or other issues exist may be ignored.  It is instead essential that data is combined with theory in order to develop correlation between factors of development as well as causation. 
In addition, when trying to explain the humanities, it is often incredibly difficult to quantify things such as culture and tradition.  This is especially true in the area of my personal research, which is about gender inequality.  The factors that measure this inequality are complex in nature and often difficult to quantify, such as patriarchal norms, or the home environment that a woman lives in.  When these aspects of the problem are ignored by solely focusing on data that is being collected, the root of the issue is not solved, which can lead to inherent harms.  It is not enough to just have data, with its tendency toward human bias and experts in the subject area.  Instead, a combination of theory and data must be used to quantify and qualify development, or lack thereof.
	The idea of “development as freedom” is introduced in a book by Amartya Sen.  Although Sen simplifies the concept of development to being the interconnected nature of freedoms including political freedom, economic freedom, and social opportunities when compared to Barder’s proposition of a complex adaptive system, Barder still acknowledges the importance of freedoms in the process of development.  When it comes to reducing unfreedoms, it is essential that the data collection methods are as accurate as possible and reducing as much bias as possible.  Hans Rosling, in his TedTalk, brought up the idea that humans are likely to make assumptions about the levels of development in certain areas of the world.  However, this is dangerous because then aid and work towards solutions are not going to be targeted toward areas where it is actually needed.  Ideas about political or gender freedoms are ones that are fundamental to human development, so if the data collected on them is not accurate, the assumptions made could just be reinforced, causing the unfreedoms in certain areas to remain unaddressed.
Returning to the example of the election, it is dangerous to assume that an area will lean toward a certain party solely based on past election data.  This election is demonstrating that demographic shifts, ideological shifts, and personal opinion in a given election cycle can lead to counties and states changing their overall trajectory.  It is essential that the data leading up to the election represents these changes so that people and candidates are as informed as in order exercise their right to political freedom in an educated manner.  This also relates to Sen’s idea of the freedom of transparency.  This freedom is greatly compromised if the information shared by reporters is based on inaccurate data, therefore harming the trust between the public and media.
With the example of gender inequality, data is often biased or not even collected about women in developing countries.  Without even having access to this data, there is no hope that the issues these women face will be able to be addressed.  As Rosling shared, assumptions can be made about countries with the most gender inequality, but it is essential that methods of data collection and data science methods, such as Bayesian geostatistical models, are utilized to create the most accurate picture of the inequalities so that they can be addressed.  Without validation of models and data, as Blumenstock asserts, biased algorithms and processes can easily skew data, especially in areas where it is already scarce to begin with and these regions will not receive the aid they need to progress towards a more developed and complex state.
	Overall, data science will play an ever-increasing role in improving the human condition.  The human population is continuing to increase and, with each new person, the complex nature of development increases, almost in a positive feedback loop as West describes, with complexity feeding into more complexity.  It is then essential that methods of data collection and data analysis are created to make sense of the increasing amount of information circulating throughout society in order to have the address the many problems that exist within our world.  However, even though it is becoming more essential to have access to data and data science methods, it is also important to recognize that there are limitations even to this vast sum of knowledge and information.  Human thought and recognition of causes of development patterns will continue to be essential even as the world becomes increasingly complex along with the data science that serves to make sense of that complexity.

